import time
import random
import streamlit as st
from openai import OpenAI
from openai import RateLimitError, APIError, APITimeoutError

# -----------------------------
# ì„¤ì •
# -----------------------------
DEFAULT_MODEL = "gpt-4o-mini"   # ê°€ëŠ¥í•˜ë©´ ì´ê±¸ ê¶Œì¥ (gpt-3.5-turboëŠ” êµ¬í™˜ê²½ì—ì„œ ì—ëŸ¬/ì œí•œì´ ë” ì¦ì„ ìˆ˜ ìˆìŒ)
COOLDOWN_SEC = 1.0             # ì—°ì† ì „ì†¡ ë°©ì§€(ì„¸ì…˜ë‹¹)

# -----------------------------
# ë°±ì˜¤í”„ ë˜í¼
# -----------------------------
def with_backoff(call_fn, max_retries: int = 5):
    """
    429(RateLimit)ë‚˜ ì¼ì‹œì ì¸ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ì— ëŒ€í•´ ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„.
    """
    for i in range(max_retries):
        try:
            return call_fn()
        except (RateLimitError, APITimeoutError, APIError) as e:
            # ë§ˆì§€ë§‰ì´ë©´ ê·¸ëŒ€ë¡œ raise
            if i == max_retries - 1:
                raise
            sleep = (2 ** i) + random.random()
            time.sleep(sleep)

# -----------------------------
# UI
# -----------------------------
st.title("ğŸ’¬ Chatbot")
st.write(
    "This is a simple chatbot that uses OpenAI to generate responses. "
    "To use this app, provide an OpenAI API key."
)

# Streamlit Cloudì—ì„œëŠ” Secrets ê¶Œì¥:
# st.secrets["OPENAI_API_KEY"] ë¥¼ ë¨¼ì € ì‹œë„í•˜ê³ , ì—†ìœ¼ë©´ ì…ë ¥ë°›ê¸°
secret_key = None
try:
    secret_key = st.secrets.get("OPENAI_API_KEY", None)
except Exception:
    secret_key = None

openai_api_key = secret_key or st.text_input("OpenAI API Key", type="password")

if not openai_api_key:
    st.info("Please add your OpenAI API key to continue.", icon="ğŸ—ï¸")
    st.stop()

# Create an OpenAI client.
client = OpenAI(api_key=openai_api_key)

# Session state ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "last_send_ts" not in st.session_state:
    st.session_state.last_send_ts = 0.0

# ê¸°ì¡´ ë©”ì‹œì§€ ë Œë”
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì…ë ¥
if prompt := st.chat_input("What is up?"):
    # ì¿¨ë‹¤ìš´ (ë„ˆë¬´ ë¹ ë¥¸ ì—°ì† ì „ì†¡ ë°©ì§€)
    now = time.time()
    if now - st.session_state.last_send_ts < COOLDOWN_SEC:
        st.warning("ì ê¹ë§Œìš”. ë„ˆë¬´ ë¹ ë¥´ê²Œ ì—°ì† ì „ì†¡ ì¤‘ì´ì—ìš”.")
        st.stop()
    st.session_state.last_send_ts = now

    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥/í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # assistant ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        try:
            # ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ (ë°±ì˜¤í”„ í¬í•¨)
            def _stream_call():
                return client.chat.completions.create(
                    model=DEFAULT_MODEL,
                    messages=[
                        {"role": m["role"], "content": m["content"]}
                        for m in st.session_state.messages
                    ],
                    stream=True,
                    # í•„ìš”í•˜ë©´ í† í° ì œí•œ ì¶”ê°€:
                    # max_tokens=400,
                )

            stream = with_backoff(_stream_call)

            # ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
            response = st.write_stream(stream)

        except RateLimitError:
            # 429ë©´ ì•ˆë‚´ ë©”ì‹œì§€
            st.error(
                "ìš”ì²­ì´ ë„ˆë¬´ ë§ì•„(OpenAI Rate Limit) ì ì‹œ ì°¨ë‹¨ëì–´ìš”. "
                "ëª‡ ì´ˆ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
            )
            st.stop()

        except Exception as e:
            # ìŠ¤íŠ¸ë¦¬ë°ì´ ì‹¤íŒ¨í•  ìˆ˜ ìˆìœ¼ë‹ˆ non-stream fallback
            st.warning("ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì— ì‹¤íŒ¨í•´ì„œ ì¼ë°˜ ì‘ë‹µìœ¼ë¡œ ì¬ì‹œë„í• ê²Œìš”.")
            try:
                def _non_stream_call():
                    return client.chat.completions.create(
                        model=DEFAULT_MODEL,
                        messages=[
                            {"role": m["role"], "content": m["content"]}
                            for m in st.session_state.messages
                        ],
                        stream=False,
                    )
                resp = with_backoff(_non_stream_call)
                response = resp.choices[0].message.content
                st.markdown(response)
            except Exception as e2:
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {type(e2).__name__}")
                st.stop()

    # ì‘ë‹µ ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": response})
